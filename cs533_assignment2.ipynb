{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS533 Assignment 2\n",
        "---\n",
        "### Course No: CS533\n",
        "### Assingment No: 2\n",
        "\n",
        "<br>\n",
        "\n",
        "### Student Name: Hasan Alp Caferoğlu\n",
        "### Student ID: 22203991\n",
        "### Email Address:  alp.caferoglu@bilkent.edu.tr\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-1l8Lqf0drj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1xBTQGv5nuq",
        "outputId": "97a6469a-8a81-462b-d944-1a434e17449b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank-bm25) (1.23.5)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.10)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2\n",
            "time: 344 µs (started: 2023-11-26 17:00:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install rank-bm25\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Mf-OvI7lH1",
        "outputId": "37229aa4-fb63-4380-f590-af6150509021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 19.8 s (started: 2023-11-26 17:00:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CISI_documents_path = '/content/drive/MyDrive/1.MS/CS533_IRS/assignments/assignment2/implementation/CISI/documents.csv'\n",
        "CISI_queries_path = '/content/drive/MyDrive/1.MS/CS533_IRS/assignments/assignment2/implementation/CISI/queries.csv'\n",
        "CISI_ground_truth_path = '/content/drive/MyDrive/1.MS/CS533_IRS/assignments/assignment2/implementation/CISI/ground_truth.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIuSGpy44XiY",
        "outputId": "877e022c-b87c-4481-cd08-26c3ba3e4832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.91 s (started: 2023-11-26 17:00:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from rank_bm25 import BM25Okapi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Downloading NLTK resources\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywvomlVT5cxZ",
        "outputId": "cf2c8b6f-705d-4cff-c0f8-f32866e541b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.51 s (started: 2023-11-26 17:00:56 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reading CSV files into Pandas DataFrames\n",
        "documents_df = pd.read_csv(CISI_documents_path)\n",
        "queries_df = pd.read_csv(CISI_queries_path)\n",
        "ground_truth_df = pd.read_csv(CISI_ground_truth_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_gTdtSixOqY",
        "outputId": "d65f4f0a-de9e-44b7-b7bd-7d5f07cd80af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 678 µs (started: 2023-11-26 17:00:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Tokenization function\n",
        "def tokenizerFunction(textData):\n",
        "  \"\"\"\n",
        "    Splitting of a sentence into its words and returns list of words\n",
        "\n",
        "    Parameters:\n",
        "    - textData: list, sentence that will be tokenized\n",
        "\n",
        "    Returns:\n",
        "    - tokens, list of tokens\n",
        "  \"\"\"\n",
        "  tokens = textData.split()\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NGPSqBn-c6v",
        "outputId": "c34780b8-226d-4056-fb81-db8583a68f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.63 ms (started: 2023-11-26 17:00:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing function\n",
        "def preprocessFunction(textData):\n",
        "  \"\"\"\n",
        "    Applying preprocessing to the given sentence.\n",
        "    Preprocessing involves removing stop words, removing punctuation marks\n",
        "    and lowercasing the text.\n",
        "\n",
        "    Parameters:\n",
        "    - textData: list, sentence that will be preprocessed\n",
        "\n",
        "    Returns:\n",
        "    - processedTextData as string\n",
        "  \"\"\"\n",
        "  # Converting text to lowercase\n",
        "  if isinstance(textData, str):\n",
        "    textData = textData.lower()\n",
        "\n",
        "    # Removing punctuations\n",
        "    # textData = textData.translate(str.maketrans('', '', string.punctuation)) # converts \"don't\" to \"dont\"\n",
        "    textData = textData.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))) # converts \"don't\" to \"don t\"\n",
        "\n",
        "    # Removing stopwords\n",
        "    stopWordsSet = set(stopwords.words('english'))\n",
        "    tokens = tokenizerFunction(textData)\n",
        "    tokens = [token for token in tokens if token not in stopWordsSet]\n",
        "\n",
        "    processedTextData = ' '.join(tokens)\n",
        "    return processedTextData\n",
        "  else:\n",
        "    # if the text data is NaN return empty string\n",
        "    return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eulR48NSk3tt",
        "outputId": "bed09ea1-5fc5-4b2e-82ab-4b28e09d8f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.27 s (started: 2023-11-26 17:00:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing 'text' column in each DataFrame\n",
        "documents_df['processedText'] = documents_df['text'].apply(preprocessFunction)\n",
        "documents_df['processedTitle'] = documents_df['title'].apply(preprocessFunction)\n",
        "queries_df['processedText'] = queries_df['text'].apply(preprocessFunction)\n",
        "\n",
        "# Storing tokens of processed text\n",
        "documents_df['processedTextTokens'] = documents_df['processedText'].apply(tokenizerFunction)\n",
        "documents_df['processedTitleTokens'] = documents_df['processedTitle'].apply(tokenizerFunction)\n",
        "queries_df['processedTextTokens'] = queries_df['processedText'].apply(tokenizerFunction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC-k5iAE7_5H",
        "outputId": "904e5a1d-6ab4-47be-e271-6c7c8ea6ad59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.17 ms (started: 2023-11-26 17:00:59 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Combining processed document titles, document texts and query texts for train set\n",
        "trainDataSetTokenized =  documents_df['processedTitleTokens'].tolist() + documents_df['processedTextTokens'].tolist() + queries_df['processedTextTokens'].tolist()\n",
        "trainDataSet = documents_df['processedTitle'].tolist() + documents_df['processedText'].tolist() + queries_df['processedText'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o99ucd2O6JLz",
        "outputId": "bc494c38-defc-49dd-b21d-26fd1e4652a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5058147, 5495550)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 46 s (started: 2023-11-26 17:00:59 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Initializing Gensim Word2Vec model\n",
        "model = Word2Vec(\n",
        "    window=10, # 10 words before the target word and 10 words after it\n",
        "    min_count=2, # at least 2 words must be present in the sentence\n",
        "    workers=2, # number of used cpu threads for training,\n",
        "    vector_size=300, # vector size is set to 300 to equalize with the google model\n",
        "    epochs=50\n",
        ")\n",
        "\n",
        "# Building vocabulariy (building list of unique words)\n",
        "model.build_vocab(trainDataSetTokenized)\n",
        "model.train(trainDataSetTokenized,\n",
        "            total_examples=model.corpus_count,\n",
        "            epochs=model.epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DvYKY1yQQFma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb35d6be-7f38-4cf2-a275-31a4778b6f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "time: 8min 59s (started: 2023-11-26 17:01:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Downlading pre-trained model \"word2vec-google-news-300\"\n",
        "preTrainedGoogleNewsModel = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZGQA6nK8pta",
        "outputId": "a404ec5b-1951-4fb1-bd6e-c063b99da12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.09 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def embeddingComputationFunction(nlTokens, wvModel):\n",
        "  \"\"\"\n",
        "    Deriving the embedding for an input (a query or a document) by averaging\n",
        "    the embeddings of its constituent words.\n",
        "\n",
        "    Parameters:\n",
        "    - nlTokens: list, the tokens of input query or document for which to compute the embedding.\n",
        "    - wvModel: KeyedVectors, model that is used for computing embeddings\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray, embedding vector for a given input.\n",
        "  \"\"\"\n",
        "\n",
        "  # Filtering words that are not present in the model\n",
        "  nlTokens = [token for token in nlTokens if token in wvModel]\n",
        "\n",
        "  # Returning zero vector if there is no words that present in the model\n",
        "  if not nlTokens:\n",
        "    return np.zeros(wvModel.vector_size)\n",
        "\n",
        "  tokensEmbeddingList = [wvModel[token] for token in nlTokens]\n",
        "  # Note that average embedding is found by averaging along the column\n",
        "  avgEmbedding = np.mean(tokensEmbeddingList, axis=0)\n",
        "\n",
        "  return avgEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tbosPzyEFuas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad92a574-94d8-4ad2-cd74-b3436b28a500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 672 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# instantiate the TF-IDF vectorizer object\n",
        "tfidfVectorizer = TfidfVectorizer()\n",
        "# Learning vocabulary and idf\n",
        "tfidfVectorizer.fit(trainDataSet)\n",
        "tfidfTrainSetVector = tfidfVectorizer.transform(trainDataSet) # tfidfVector is scipy sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-3qqRDlYmk5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4110412-39b6-4a06-d023-1a3a9c8b6760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 119 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# BM25 Initializing\n",
        "bm25 = BM25Okapi(documents_df['processedTextTokens'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V74IoYwBua_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8a23f4-81c7-44b7-e65e-2bf6cae1009b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15873646896054894"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 21.4 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Calculating TF-IDF score for query-document pair\n",
        "def tfidfScoreQueryDocPair(query, doc):\n",
        "  \"\"\"\n",
        "    Obtaining tfidf score for a document query pair\n",
        "\n",
        "    Parameters:\n",
        "    - query: string, considered query\n",
        "    - docId: string, considered doc\n",
        "\n",
        "    Returns:\n",
        "    - float, tfidf score for query-document pair\n",
        "  \"\"\"\n",
        "  tfidfScore = np.dot(tfidfVectorizer.transform([doc]).toarray(), tfidfVectorizer.transform([query]).toarray().T).sum()\n",
        "  return tfidfScore\n",
        "\n",
        "# Example for TF-IDF score\n",
        "tfidfScoreQueryDocPair(queries_df['processedText'][0], documents_df['processedText'][758])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6GSMHHvEH5ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e3ed61-970f-4e42-8d24-b619c9339eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8012794563366724\n",
            "time: 42.3 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def bm25ScoreQueryDocPair(query, docId):\n",
        "  \"\"\"\n",
        "    Obtaining BM25 score for a document query pair\n",
        "\n",
        "    Parameters:\n",
        "    - query: string, the query which related documents wil be retrieved\n",
        "    - docId: int, document ID that is compared with given query\n",
        "\n",
        "    Returns:\n",
        "    - float, BM25 score for query-document pair\n",
        "  \"\"\"\n",
        "  scoreList = bm25.get_scores(query.split())\n",
        "  # normalization of score is done by dividing obtained score with max score\n",
        "  bm25Score = scoreList[docId-1] / max(scoreList)\n",
        "  return bm25Score\n",
        "\n",
        "# Example for BM25 Score\n",
        "bm25score = bm25ScoreQueryDocPair(queries_df['processedText'][0], 759)\n",
        "print(bm25score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a5uroV-Xny2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0650013f-3315-4c99-ac49-01985ea2efbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6386269\n",
            "0.68639153\n",
            "time: 14.6 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def embeddingScoreQueryDocPair(query, doc, model):\n",
        "  \"\"\"\n",
        "    Obtaining embedding score for a document query pair\n",
        "\n",
        "    Parameters:\n",
        "    - query: string, considered query\n",
        "    - doc: string, considered doc\n",
        "    - model: word2vec model that is wanted to be used\n",
        "\n",
        "    Returns:\n",
        "    - float, embedding score for query-document pair\n",
        "  \"\"\"\n",
        "  queryEmbeddings = embeddingComputationFunction(query.split(), model)\n",
        "  docEmbeddings = embeddingComputationFunction(doc.split(), model)\n",
        "  # applying cosine similarity\n",
        "  if (np.linalg.norm(queryEmbeddings) * np.linalg.norm(docEmbeddings)) != 0:\n",
        "    embeddingScore = np.dot(queryEmbeddings, docEmbeddings) / (np.linalg.norm(queryEmbeddings) * np.linalg.norm(docEmbeddings))\n",
        "    return embeddingScore\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# Example for embedding score\n",
        "embeddingScore = embeddingScoreQueryDocPair(queries_df['processedText'][0], documents_df['processedText'][758], model.wv)\n",
        "print(embeddingScore)\n",
        "embeddingScore = embeddingScoreQueryDocPair(queries_df['processedText'][0], documents_df['processedText'][758], preTrainedGoogleNewsModel)\n",
        "print(embeddingScore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3XA23FjTmvGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf9bd11-4f3b-4670-f9d3-b15113f16ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5275521236008373\n",
            "0.5433144610470501\n",
            "time: 124 ms (started: 2023-11-26 17:10:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def combinedScoreQueryDocPair(doc, query, docId, embeddingModel, tfidfWeight, bm25Weight, embeddingWeight):\n",
        "  \"\"\"\n",
        "    Obtaining total combined score for a document query pair\n",
        "\n",
        "    Parameters:\n",
        "    - doc: string, context of the doc\n",
        "    - query: string, query text\n",
        "    - docId: int, ID of considered doc\n",
        "    - embeddingModel: word2vec model that is wanted to be used\n",
        "    - tfidfWeight: float, weight for tfidf score\n",
        "    - bm25Weight: float, weight for bm25 score\n",
        "    - embeddingWeight: float, weight for embedding score\n",
        "\n",
        "    Returns:\n",
        "    - float, combined score for query-document pair\n",
        "  \"\"\"\n",
        "\n",
        "  tfidfScore = tfidfScoreQueryDocPair(query, doc)\n",
        "  bm25Score = bm25ScoreQueryDocPair(query, docId)\n",
        "  embeddingScore = embeddingScoreQueryDocPair(query, doc, embeddingModel)\n",
        "  combinedScore = tfidfWeight * tfidfScore + bm25Weight * bm25Score + embeddingWeight * embeddingScore\n",
        "  return combinedScore\n",
        "\n",
        "# Example for combined score\n",
        "docId = 759\n",
        "queryId = 1\n",
        "doc = documents_df['processedText'][docId-1]\n",
        "query = queries_df['processedText'][queryId-1]\n",
        "combinedScore = combinedScoreQueryDocPair(doc, query, docId, model.wv, 0.33, 0.33, 0.33)\n",
        "print(combinedScore)\n",
        "combinedScore = combinedScoreQueryDocPair(doc, query, docId, preTrainedGoogleNewsModel, 0.33, 0.33, 0.33)\n",
        "print(combinedScore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "maBtRdeowVZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b622c4de-aee4-4da5-ec12-8b94f84deb72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.23 ms (started: 2023-11-26 17:10:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def retrievalSystem(docDataFrame, queryDataFrame, queryId, embeddingModel, tfidfWeight, bm25Weight, embeddingWeight):\n",
        "  docScores = []\n",
        "  query = queryDataFrame['processedText'][queryId-1]\n",
        "  for docIndex in range(len(docDataFrame)):\n",
        "    docId = docIndex+1\n",
        "    doc = docDataFrame['processedText'][docId-1]\n",
        "    combinedScore = combinedScoreQueryDocPair(doc, query, docId, embeddingModel, tfidfWeight, bm25Weight, embeddingWeight)\n",
        "    docScores.append((docId, combinedScore))\n",
        "\n",
        "  sortedDocScores = sorted(docScores, key=lambda x: x[1], reverse=True)\n",
        "  top10 = [item[0] for item in sortedDocScores[:10]]\n",
        "  return top10\n",
        "\n",
        "# Examine the retrievalSystem\n",
        "# top10ForQ1 = retrievalSystem(documents_df, queries_df, 1, model.wv, 0.33, 0.33, 0.33 )\n",
        "# print(top10ForQ1)\n",
        "# top10ForQ1 = retrievalSystem(documents_df, queries_df, 1, preTrainedGoogleNewsModel, 0.33, 0.33, 0.33 )\n",
        "# print(top10ForQ1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "418nLkpERQv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452ba1b9-1bc2-4523-9007-d10e1d9b312b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.11 ms (started: 2023-11-26 17:10:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def calculateMAPForSystem(groundTruthDataFrame, docDataFrame, queryDataFrame, embeddingModel, tfidfWeight, bm25Weight, embeddingWeight):\n",
        "  # applying MAP at 10\n",
        "  avgPrecisionForQueries = []\n",
        "  # Obtaining queries and count of relevant documents\n",
        "  queryAndRelDocNum =  groundTruthDataFrame['query_id'].value_counts().reset_index().rename(columns={'query_id': 'rel_doc_count', 'index': 'query_id'})\n",
        "  queryAndRelDocNum=queryAndRelDocNum.sort_values(by='query_id').reset_index(drop=True)\n",
        "  print(queryAndRelDocNum) # DELETE LATER\n",
        "  for qIndex in range(len(queryAndRelDocNum)):\n",
        "    queryId = queryAndRelDocNum.loc[qIndex, 'query_id']\n",
        "    relevantDocIds = (groundTruthDataFrame[groundTruthDataFrame['query_id'] == queryId])['doc_id'].tolist()\n",
        "    top10RetrievedDocIds = retrievalSystem(docDataFrame, queryDataFrame, queryId, embeddingModel, tfidfWeight, bm25Weight, embeddingWeight)\n",
        "    # print('top 10 retrieved docs for query id ', queryId, \": \") # DELETE LATER\n",
        "    # print(top10RetrievedDocIds) # DELETE LATER\n",
        "\n",
        "    relevanceCount = 0\n",
        "    precisionSum = 0\n",
        "    for i in range(len(top10RetrievedDocIds)):\n",
        "      retrievedDocId = top10RetrievedDocIds[i]\n",
        "      if retrievedDocId in relevantDocIds:\n",
        "        relevanceCount+=1\n",
        "        # print(relevanceCount, \"/\", i+1, \" = \", relevanceCount / (i+1) ) # DELETE LATER\n",
        "        precisionSum += relevanceCount / (i+1)\n",
        "\n",
        "    # print('precision sum: ', precisionSum) # DELETE LATER\n",
        "    avgPrecision = precisionSum / len(relevantDocIds)\n",
        "    print('Average Precision for query id ', queryId, \": \", avgPrecision) # DELETE LATER\n",
        "    avgPrecisionForQueries.append(avgPrecision)\n",
        "    print(\"-\"*30) # DELETE LATER\n",
        "\n",
        "  print(\" Sum of average precisions: \", sum(avgPrecisionForQueries)) # DELETE LATER\n",
        "  print(\"Number of queries considered: \", len(avgPrecisionForQueries)) # DELETE LATER\n",
        "  MAP = sum(avgPrecisionForQueries) / len(avgPrecisionForQueries)\n",
        "  print('MAP for the system: ', MAP)\n",
        "  print(\"-\"*30)\n",
        "  return MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CYugSvh_S1-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605e4105-8382-4eb7-ed3d-14a7b57a7169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    query_id  rel_doc_count\n",
            "0          1             46\n",
            "1          2             26\n",
            "2          3             44\n",
            "3          4              8\n",
            "4          5             24\n",
            "..       ...            ...\n",
            "71       101              1\n",
            "72       102             24\n",
            "73       104             11\n",
            "74       109             71\n",
            "75       111              6\n",
            "\n",
            "[76 rows x 2 columns]\n",
            "Average Precision for query id  1 :  0.10429606625258799\n",
            "------------------------------\n",
            "Average Precision for query id  2 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  3 :  0.11875\n",
            "------------------------------\n",
            "Average Precision for query id  4 :  0.08660714285714285\n",
            "------------------------------\n",
            "Average Precision for query id  5 :  0.013888888888888888\n",
            "------------------------------\n",
            "Average Precision for query id  6 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  7 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  8 :  0.005555555555555556\n",
            "------------------------------\n",
            "Average Precision for query id  9 :  0.055882352941176466\n",
            "------------------------------\n",
            "Average Precision for query id  10 :  0.08076923076923077\n",
            "------------------------------\n",
            "Average Precision for query id  11 :  0.019597550306211724\n",
            "------------------------------\n",
            "Average Precision for query id  12 :  0.02564102564102564\n",
            "------------------------------\n",
            "Average Precision for query id  13 :  0.03668236525379382\n",
            "------------------------------\n",
            "Average Precision for query id  14 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  15 :  0.04181184668989547\n",
            "------------------------------\n",
            "Average Precision for query id  16 :  0.019230769230769232\n",
            "------------------------------\n",
            "Average Precision for query id  17 :  0.038461538461538464\n",
            "------------------------------\n",
            "Average Precision for query id  18 :  0.045454545454545456\n",
            "------------------------------\n",
            "Average Precision for query id  19 :  0.054085831863609636\n",
            "------------------------------\n",
            "Average Precision for query id  20 :  0.02827380952380952\n",
            "------------------------------\n",
            "Average Precision for query id  21 :  0.013333333333333332\n",
            "------------------------------\n",
            "Average Precision for query id  22 :  0.013626834381551363\n",
            "------------------------------\n",
            "Average Precision for query id  23 :  0.03958333333333333\n",
            "------------------------------\n",
            "Average Precision for query id  24 :  0.0889423076923077\n",
            "------------------------------\n",
            "Average Precision for query id  25 :  0.10548340548340547\n",
            "------------------------------\n",
            "Average Precision for query id  26 :  0.15694444444444447\n",
            "------------------------------\n",
            "Average Precision for query id  27 :  0.025603864734299518\n",
            "------------------------------\n",
            "Average Precision for query id  28 :  0.06736111111111111\n",
            "------------------------------\n",
            "Average Precision for query id  29 :  0.03125\n",
            "------------------------------\n",
            "Average Precision for query id  30 :  0.0664179104477612\n",
            "------------------------------\n",
            "Average Precision for query id  31 :  0.02459016393442623\n",
            "------------------------------\n",
            "Average Precision for query id  32 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  33 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  34 :  0.0647451963241437\n",
            "------------------------------\n",
            "Average Precision for query id  35 :  0.0694905869324474\n",
            "------------------------------\n",
            "Average Precision for query id  37 :  0.013333333333333332\n",
            "------------------------------\n",
            "Average Precision for query id  39 :  0.1111111111111111\n",
            "------------------------------\n",
            "Average Precision for query id  41 :  0.06565656565656565\n",
            "------------------------------\n",
            "Average Precision for query id  42 :  0.07795238095238095\n",
            "------------------------------\n",
            "Average Precision for query id  43 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  44 :  0.03299539170506912\n",
            "------------------------------\n",
            "Average Precision for query id  45 :  0.05476190476190476\n",
            "------------------------------\n",
            "Average Precision for query id  46 :  0.043318965517241376\n",
            "------------------------------\n",
            "Average Precision for query id  49 :  0.04901960784313725\n",
            "------------------------------\n",
            "Average Precision for query id  50 :  0.07660959514892098\n",
            "------------------------------\n",
            "Average Precision for query id  52 :  0.5051851851851852\n",
            "------------------------------\n",
            "Average Precision for query id  54 :  0.011437908496732025\n",
            "------------------------------\n",
            "Average Precision for query id  55 :  0.4263888888888889\n",
            "------------------------------\n",
            "Average Precision for query id  56 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  57 :  0.1111111111111111\n",
            "------------------------------\n",
            "Average Precision for query id  58 :  0.14330572808833678\n",
            "------------------------------\n",
            "Average Precision for query id  61 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  62 :  0.35763888888888884\n",
            "------------------------------\n",
            "Average Precision for query id  65 :  0.15384615384615385\n",
            "------------------------------\n",
            "Average Precision for query id  66 :  0.09489795918367346\n",
            "------------------------------\n",
            "Average Precision for query id  67 :  0.03255208333333333\n",
            "------------------------------\n",
            "Average Precision for query id  69 :  0.16574074074074072\n",
            "------------------------------\n",
            "Average Precision for query id  71 :  0.15637860082304528\n",
            "------------------------------\n",
            "Average Precision for query id  76 :  0.05327380952380952\n",
            "------------------------------\n",
            "Average Precision for query id  79 :  0.16017316017316016\n",
            "------------------------------\n",
            "Average Precision for query id  81 :  0.09090909090909091\n",
            "------------------------------\n",
            "Average Precision for query id  82 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  84 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  90 :  0.009841269841269842\n",
            "------------------------------\n",
            "Average Precision for query id  92 :  0.0625\n",
            "------------------------------\n",
            "Average Precision for query id  95 :  0.09292929292929292\n",
            "------------------------------\n",
            "Average Precision for query id  96 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  97 :  0.25\n",
            "------------------------------\n",
            "Average Precision for query id  98 :  0.1256431308155446\n",
            "------------------------------\n",
            "Average Precision for query id  99 :  0.08137254901960785\n",
            "------------------------------\n",
            "Average Precision for query id  100 :  0.02976190476190476\n",
            "------------------------------\n",
            "Average Precision for query id  101 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  102 :  0.27645502645502645\n",
            "------------------------------\n",
            "Average Precision for query id  104 :  0.01515151515151515\n",
            "------------------------------\n",
            "Average Precision for query id  109 :  0.05888665325285044\n",
            "------------------------------\n",
            "Average Precision for query id  111 :  0.2333333333333333\n",
            "------------------------------\n",
            " Sum of average precisions:  5.765833852624507\n",
            "Number of queries considered:  76\n",
            "MAP for the system:  0.07586623490295404\n",
            "------------------------------\n",
            "System 1: \n",
            " MAP: 0.07586623490295404 Weights: (0.4, 0.25, 0.35) Embedding Model: KeyedVectors<vector_size=300, 5978 keys> \n",
            "\n",
            "    query_id  rel_doc_count\n",
            "0          1             46\n",
            "1          2             26\n",
            "2          3             44\n",
            "3          4              8\n",
            "4          5             24\n",
            "..       ...            ...\n",
            "71       101              1\n",
            "72       102             24\n",
            "73       104             11\n",
            "74       109             71\n",
            "75       111              6\n",
            "\n",
            "[76 rows x 2 columns]\n",
            "Average Precision for query id  1 :  0.10108695652173912\n",
            "------------------------------\n",
            "Average Precision for query id  2 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  3 :  0.10511363636363637\n",
            "------------------------------\n",
            "Average Precision for query id  4 :  0.040625\n",
            "------------------------------\n",
            "Average Precision for query id  5 :  0.025793650793650796\n",
            "------------------------------\n",
            "Average Precision for query id  6 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  7 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  8 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  9 :  0.05710784313725489\n",
            "------------------------------\n",
            "Average Precision for query id  10 :  0.13685897435897434\n",
            "------------------------------\n",
            "Average Precision for query id  11 :  0.023097112860892388\n",
            "------------------------------\n",
            "Average Precision for query id  12 :  0.038461538461538464\n",
            "------------------------------\n",
            "Average Precision for query id  13 :  0.040170940170940174\n",
            "------------------------------\n",
            "Average Precision for query id  14 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  15 :  0.01016260162601626\n",
            "------------------------------\n",
            "Average Precision for query id  16 :  0.038461538461538464\n",
            "------------------------------\n",
            "Average Precision for query id  17 :  0.038461538461538464\n",
            "------------------------------\n",
            "Average Precision for query id  18 :  0.045454545454545456\n",
            "------------------------------\n",
            "Average Precision for query id  19 :  0.054389574759945124\n",
            "------------------------------\n",
            "Average Precision for query id  20 :  0.0163966049382716\n",
            "------------------------------\n",
            "Average Precision for query id  21 :  0.02\n",
            "------------------------------\n",
            "Average Precision for query id  22 :  0.00646900269541779\n",
            "------------------------------\n",
            "Average Precision for query id  23 :  0.06375661375661376\n",
            "------------------------------\n",
            "Average Precision for query id  24 :  0.0889423076923077\n",
            "------------------------------\n",
            "Average Precision for query id  25 :  0.08619528619528619\n",
            "------------------------------\n",
            "Average Precision for query id  26 :  0.12103174603174603\n",
            "------------------------------\n",
            "Average Precision for query id  27 :  0.02608695652173913\n",
            "------------------------------\n",
            "Average Precision for query id  28 :  0.07996031746031745\n",
            "------------------------------\n",
            "Average Precision for query id  29 :  0.024305555555555552\n",
            "------------------------------\n",
            "Average Precision for query id  30 :  0.056210021321961616\n",
            "------------------------------\n",
            "Average Precision for query id  31 :  0.0273224043715847\n",
            "------------------------------\n",
            "Average Precision for query id  32 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  33 :  0.005555555555555555\n",
            "------------------------------\n",
            "Average Precision for query id  34 :  0.041071428571428564\n",
            "------------------------------\n",
            "Average Precision for query id  35 :  0.07170542635658914\n",
            "------------------------------\n",
            "Average Precision for query id  37 :  0.00625\n",
            "------------------------------\n",
            "Average Precision for query id  39 :  0.07407407407407407\n",
            "------------------------------\n",
            "Average Precision for query id  41 :  0.07142857142857142\n",
            "------------------------------\n",
            "Average Precision for query id  42 :  0.041999999999999996\n",
            "------------------------------\n",
            "Average Precision for query id  43 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  44 :  0.028207885304659494\n",
            "------------------------------\n",
            "Average Precision for query id  45 :  0.03209647495361781\n",
            "------------------------------\n",
            "Average Precision for query id  46 :  0.03814655172413793\n",
            "------------------------------\n",
            "Average Precision for query id  49 :  0.09033613445378151\n",
            "------------------------------\n",
            "Average Precision for query id  50 :  0.07495541287676119\n",
            "------------------------------\n",
            "Average Precision for query id  52 :  0.3527777777777778\n",
            "------------------------------\n",
            "Average Precision for query id  54 :  0.008278867102396514\n",
            "------------------------------\n",
            "Average Precision for query id  55 :  0.3819444444444444\n",
            "------------------------------\n",
            "Average Precision for query id  56 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  57 :  0.10925925925925925\n",
            "------------------------------\n",
            "Average Precision for query id  58 :  0.09484989648033126\n",
            "------------------------------\n",
            "Average Precision for query id  61 :  0.009090909090909092\n",
            "------------------------------\n",
            "Average Precision for query id  62 :  0.33796296296296297\n",
            "------------------------------\n",
            "Average Precision for query id  65 :  0.15384615384615385\n",
            "------------------------------\n",
            "Average Precision for query id  66 :  0.08333333333333333\n",
            "------------------------------\n",
            "Average Precision for query id  67 :  0.016666666666666666\n",
            "------------------------------\n",
            "Average Precision for query id  69 :  0.17407407407407405\n",
            "------------------------------\n",
            "Average Precision for query id  71 :  0.16131687242798354\n",
            "------------------------------\n",
            "Average Precision for query id  76 :  0.041190476190476194\n",
            "------------------------------\n",
            "Average Precision for query id  79 :  0.16623376623376623\n",
            "------------------------------\n",
            "Average Precision for query id  81 :  0.09090909090909091\n",
            "------------------------------\n",
            "Average Precision for query id  82 :  0.025\n",
            "------------------------------\n",
            "Average Precision for query id  84 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  90 :  0.005215419501133786\n",
            "------------------------------\n",
            "Average Precision for query id  92 :  0.09999999999999999\n",
            "------------------------------\n",
            "Average Precision for query id  95 :  0.10303030303030303\n",
            "------------------------------\n",
            "Average Precision for query id  96 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  97 :  0.25\n",
            "------------------------------\n",
            "Average Precision for query id  98 :  0.1116584564860427\n",
            "------------------------------\n",
            "Average Precision for query id  99 :  0.10259103641456582\n",
            "------------------------------\n",
            "Average Precision for query id  100 :  0.05\n",
            "------------------------------\n",
            "Average Precision for query id  101 :  0.0\n",
            "------------------------------\n",
            "Average Precision for query id  102 :  0.2732142857142857\n",
            "------------------------------\n",
            "Average Precision for query id  104 :  0.018181818181818184\n",
            "------------------------------\n",
            "Average Precision for query id  109 :  0.029733959311424096\n",
            "------------------------------\n",
            "Average Precision for query id  111 :  0.2333333333333333\n",
            "------------------------------\n",
            " Sum of average precisions:  5.431442946044721\n",
            "Number of queries considered:  76\n",
            "MAP for the system:  0.07146635455322002\n",
            "------------------------------\n",
            "System 2: \n",
            " MAP: 0.07146635455322002 Weights: (0.4, 0.25, 0.35) Embedding Model: KeyedVectors<vector_size=300, 3000000 keys> \n",
            "\n",
            "time: 2h 43min 27s (started: 2023-11-26 17:10:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "embeddingModels = [model.wv, preTrainedGoogleNewsModel]\n",
        "systemsWeightList = [(0.4, 0.25, 0.35)]\n",
        "\n",
        "systemsDict = {}\n",
        "sysCount = 1\n",
        "for index in range(len(systemsWeightList)):\n",
        "  system = {'embeddingModel': 0, 'weights': systemsWeightList[index]}\n",
        "  systemsDict[f'{sysCount}'] = system\n",
        "  sysCount+=1\n",
        "\n",
        "  # if embeddingWeight is larger than 0, there must 2 systems with both our trained model and pretrained model\n",
        "  if systemsWeightList[index][2] > 0:\n",
        "    systemWithAnotherModel = {'embeddingModel': 1, 'weights': systemsWeightList[index]}\n",
        "    systemsDict[f'{sysCount}'] = systemWithAnotherModel\n",
        "    sysCount+=1\n",
        "\n",
        "\n",
        "# print(systemsDict)\n",
        "# print(len(systemsDict))\n",
        "for systemId in range(1, len(systemsDict)+1):\n",
        "  system = systemsDict[f'{systemId}']\n",
        "  weights = system['weights']\n",
        "  tfidfWeight, bm25Weight, embeddingWeight = system['weights']\n",
        "  embeddingModelNo = system['embeddingModel']\n",
        "  MAP = calculateMAPForSystem(ground_truth_df, documents_df, queries_df, embeddingModels[embeddingModelNo], tfidfWeight, bm25Weight, embeddingWeight)\n",
        "  system['MAP'] = MAP\n",
        "  print(f'System {systemId}: \\n MAP: {MAP} Weights: {weights} Embedding Model: {embeddingModels[embeddingModelNo]} \\n')\n",
        "\n",
        "\n",
        "# Printing System Performances into txt file\n",
        "systemPerformanceFilePath = '/content/drive/MyDrive/1.MS/CS533_IRS/assignments/assignment2/implementation/systemPerformances6.txt'\n",
        "with open(systemPerformanceFilePath, 'w') as fileHandle:\n",
        "  for systemId, system in systemsDict.items():\n",
        "    weights = system['weights']\n",
        "    MAP = system['MAP']\n",
        "    embeddingModelId = system['embeddingModel']\n",
        "    if embeddingModelId == 1:\n",
        "      embeddingModel = 'Trained Model with CISI Dataset'\n",
        "    else:\n",
        "      embeddingModel = 'word2vec-google-news-300'\n",
        "    line = f'System {systemId}: \\n MAP: {MAP} Weights: {weights} Embedding Model: {embeddingModel} \\n'\n",
        "    fileHandle.write(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH317jfvYypX",
        "outputId": "b073f920-af7a-4271-b702-1c63aa5c7fde"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2h 43min 27s (started: 2023-11-26 17:10:46 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}